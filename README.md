**DATA QUALITY CONTROL**

**Project Description: **Data Quality Control Initiative at UCW.

**Project Title:** Implementation of Data Quality Control Measures at UCW

**Objective:** The primary objective of this project is to establish a comprehensive Data Quality Control (DQPC) framework at UCW. This framework will ensure the accuracy, completeness, consistency, and reliability of the organization's data, enhancing decision-making processes and overall performance of the HR department.

**Background: **As UCW continues to expand its data sources, issues related to data quality have surfaced, including inaccuracies, duplicate records, and inconsistent formats. Poor data quality can lead to misguided strategies, inefficiencies, and regulatory compliance risks. This project aims to implement robust data quality control measures to mitigate these issues.

**Scope:** The project will focus on the following key areas:

o	Data Profiling: Analyzing existing datasets to assess quality levels.

o	Data Cleansing: Developing processes to correct inaccuracies and eliminate duplicates.

o	Data Validation: Implementing validation rules and checks to ensure data integrity.

o	Monitoring and Reporting: Establishing ongoing monitoring processes and dashboards to track data quality metrics.

**Dataset includes:**

o	Violation id - it's a unique id to find the reports

o	Student id - the student who gave the report

o	Name - name of the reporter

o	Violation type - what kind of violation is it?

o	Date of violation - which day this violation has occurred

o	Resolution date - the final resolution day

**Methodology:**

1-	**Current State Assessment:**

This is a sample dataset I have used for my project.

<img width="468" alt="image" src="https://github.com/user-attachments/assets/144e7e29-d863-40dd-a874-bd1fc88ddaec">

o	Conducted a thorough analysis of current data sources, workflows, and existing data quality challenges.
o	Identified the key datasets that significantly impact the resolution for the violation report.

2-**	Data Profiling:**

<img width="468" alt="image" src="https://github.com/user-attachments/assets/f78acf46-1c65-4427-bd04-397482178a3f">

o	Utilize data profiling tools such as Data Brew service to create a profile overview and check the quality of the profile and to assess the quality of identified datasets, focusing on completeness, uniqueness, validity, consistency, and accuracy.

3-	**Establish Data Quality Metrics:**

<img width="468" alt="image" src="https://github.com/user-attachments/assets/33ca5285-cd08-49ee-95a8-520aef177dce">

o	Defined clear data quality metrics and key performance indicators (KPIs) to evaluate and track data quality over time, such as error rates, duplicate records, and compliance with data standards.
**
4-	Data Cleansing Processes:**

<img width="468" alt="image" src="https://github.com/user-attachments/assets/b6dbc9e1-2fb5-4e37-94a8-9f7873758455">

Develop and implement procedures for data cleansing, which may include:

o	Removing duplicates and correcting errors.
o	Standardizing data formats and values.
o	Filling in missing values using appropriate imputation techniques.

**5-	Validation Rules and Procedures:**

<img width="468" alt="image" src="https://github.com/user-attachments/assets/05667b5f-a594-4e71-9d4d-d45faecc9b20">

o	Set up validation rules for new data entries to reduce the risk of poor-quality data being introduced into the system.

**6-	Monitoring and Reporting:**

Dashboard - 1

<img width="452" alt="image" src="https://github.com/user-attachments/assets/4f5ebd5b-7726-4cfd-aa85-00a7b6034513">

Dashboard - 2

<img width="452" alt="image" src="https://github.com/user-attachments/assets/741b8f9e-af82-4ff6-8e87-d64b298a19d3">

o	Implemented monitoring tools and dashboards that provide real-time data quality metrics and alerts for significant deviations by using AWS cloud watch service.
o	Schedule regular reports to review data quality trends and performance against established KPIs.

**Tools and Technologies:**

AWS - S3 - AWS Brew - AWS Glue - AWS Athena - AWS cloud watch
**
Deliverables:**

•	A comprehensive Data Quality Control plan detailing processes, metrics, and responsibilities.
•	Documentation of data quality metrics and KPIs being tracked.
•	Cleaned and validated datasets ready for analysis and reporting.
•	A monitoring dashboard that visualizes data quality metrics in real-time.

**Timeline:**

•	Expected completion of the project: 10 weeks, including assessment, implementation, and monitoring setup.
This Data Quality Control initiative aims to mitigate the violation reports at UCW to enhance its data integrity and reliability, resulting in improved decision-making, operational efficiency, and compliance with regulatory requirements.
















